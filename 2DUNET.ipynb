{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TUYOcElVgJTk",
        "outputId": "5a62de0e-510f-4d73-cbd9-c066a49d1666"
      },
      "outputs": [],
      "source": [
        "! pip install visdom==0.1.7 wandb rasterio\n",
        "!pip install einops\n",
        "!pip install einsum"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NSIfpgc-esut"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "import torch.nn.functional\n",
        "import torch.nn.functional as F\n",
        "from torch import autograd\n",
        "import torch.optim as optim\n",
        "\n",
        "import os\n",
        "from glob import glob\n",
        "from datetime import datetime\n",
        "from sklearn.metrics import confusion_matrix, f1_score, accuracy_score\n",
        "from sklearn.model_selection import GroupShuffleSplit\n",
        "from matplotlib import pyplot as plt\n",
        "plt.switch_backend('agg')\n",
        "\n",
        "import visdom\n",
        "from torchvision.utils import save_image, make_grid\n",
        "import datetime\n",
        "import pickle\n",
        "from tqdm import tqdm\n",
        "import itertools\n",
        "import wandb\n",
        "import math\n",
        "from einops import rearrange\n",
        "\n",
        "import argparse\n",
        "import pandas as pd\n",
        "import time\n",
        "import random\n",
        "from datetime import datetime\n",
        "import rasterio\n",
        "from pathlib import Path\n",
        "\n",
        "from PIL import Image\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn.utils.rnn as rnn\n",
        "import json\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data.sampler import WeightedRandomSampler, SubsetRandomSampler\n",
        "from torchvision import models\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A3dU0Zi89g1j",
        "outputId": "ba1ed545-b28c-45df-b5e4-06306c1ff2d3"
      },
      "outputs": [],
      "source": [
        "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(\"Device: \", DEVICE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1YOZuJC1SXNw"
      },
      "outputs": [],
      "source": [
        "# BAND STATS\n",
        "\n",
        "BANDS = { 's1': { 'VV': 0, 'VH': 1, 'RATIO': 2},\n",
        "          's2': { '10': {'BLUE': 0, 'GREEN': 1, 'RED': 2, 'RDED1': 3, 'RDED2': 4, 'RDED3': 5, 'NIR': 6, 'RDED4': 7, 'SWIR1': 8, 'SWIR2': 9},\n",
        "                   '4': {'BLUE': 0, 'GREEN': 1, 'RED': 2, 'NIR': 3}},\n",
        "          'planet': { '4': {'BLUE': 0, 'GREEN': 1, 'RED': 2, 'NIR': 3}}}\n",
        "\n",
        "MEANS = { 's1': { 'ghana': torch.Tensor([-10.50, -17.24, 1.17]),\n",
        "                  'southsudan': torch.Tensor([-9.02, -15.26, 1.15])},\n",
        "          's2': { 'ghana': torch.Tensor([2620.00, 2519.89, 2630.31, 2739.81, 3225.22, 3562.64, 3356.57, 3788.05, 2915.40, 2102.65]),\n",
        "                  'southsudan': torch.Tensor([2119.15, 2061.95, 2127.71, 2277.60, 2784.21, 3088.40, 2939.33, 3308.03, 2597.14, 1834.81])},\n",
        "          'planet': { 'ghana': torch.Tensor([1264.81, 1255.25, 1271.10, 2033.22]),\n",
        "                      'southsudan': torch.Tensor([1091.30, 1092.23, 1029.28, 2137.77])},\n",
        "          's2_cldfltr': { 'ghana': torch.Tensor([1362.68, 1317.62, 1410.74, 1580.05, 2066.06, 2373.60, 2254.70, 2629.11, 2597.50, 1818.43]),\n",
        "                  'southsudan': torch.Tensor([1137.58, 1127.62, 1173.28, 1341.70, 1877.70, 2180.27, 2072.11, 2427.68, 2308.98, 1544.26])} }\n",
        "\n",
        "STDS = { 's1': { 'ghana': torch.Tensor([3.57, 4.86, 5.60]),\n",
        "                 'southsudan': torch.Tensor([4.49, 6.68, 21.75])},\n",
        "         's2': { 'ghana': torch.Tensor([2171.62, 2085.69, 2174.37, 2084.56, 2058.97, 2117.31, 1988.70, 2099.78, 1209.48, 918.19]),\n",
        "                 'southsudan': torch.Tensor([2113.41, 2026.64, 2126.10, 2093.35, 2066.81, 2114.85, 2049.70, 2111.51, 1320.97, 1029.58])},\n",
        "         'planet': { 'ghana': torch.Tensor([602.51, 598.66, 637.06, 966.27]),\n",
        "                     'southsudan': torch.Tensor([526.06, 517.05, 543.74, 1022.14])},\n",
        "         's2_cldfltr': { 'ghana': torch.Tensor([511.19, 495.87, 591.44, 590.27, 745.81, 882.05, 811.14, 959.09, 964.64, 809.53]),\n",
        "                 'southsudan': torch.Tensor([548.64, 547.45, 660.28, 677.55, 896.28, 1066.91, 1006.01, 1173.19, 1167.74, 865.42])} }\n",
        "\n",
        "# OTHER PER COUNTRY CONSTANTS\n",
        "NUM_CLASSES = { 'ghana': 4,\n",
        "                'southsudan': 4}\n",
        "\n",
        "GRID_SIZE = { 'ghana': 256,\n",
        "              'southsudan': 256}\n",
        "\n",
        "\n",
        "CROPS = { 'ghana': ['groundnut', 'maize', 'rice', 'soya bean'],\n",
        "          'southsudan': ['sorghum', 'maize', 'rice', 'groundnut']}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ptixpERuqUjn"
      },
      "outputs": [],
      "source": [
        "class CropTypeMappingDataset():\n",
        "\n",
        "    def __init__(self, ):\n",
        "\n",
        "        self.data_dir = '/content/data/africa_crop_type_mapping' # 'gs://data_ctm/data/africa_crop_type_mapping'\n",
        "\n",
        "        self.split_dict = {'train': 0, 'val': 1, 'test': 2}\n",
        "        self.split_names = {'train': 'Train', 'val': 'Validation', 'test': 'Test'}\n",
        "\n",
        "        # Extract splits\n",
        "        split_df = pd.read_csv(os.path.join(self.data_dir, 'ghana', 'list_eval_partition.csv'))\n",
        "\n",
        "        self.split_array = split_df['partition'].values\n",
        "\n",
        "\n",
        "        # y_array stores idx ids corresponding to location. Actual y labels are\n",
        "        # tensors that are loaded separately.\n",
        "        self.y_array = torch.from_numpy(split_df['id'].values)\n",
        "\n",
        "        self.y_size = (64, 64)\n",
        "\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Any transformations are handled by the SustainBenchSubset\n",
        "        # since different subsets (e.g., train vs test) might have different transforms\n",
        "        x = self.get_input(idx)\n",
        "        y = self.get_label(idx)\n",
        "        return x, y\n",
        "\n",
        "\n",
        "    def get_input(self, idx):\n",
        "        \"\"\"\n",
        "        Returns X for a given idx.\n",
        "        \"\"\"\n",
        "        loc_id = f'{self.y_array[idx]:06d}'\n",
        "\n",
        "        images = np.load(os.path.join(self.data_dir, 'ghana', 'npy', f'{\"ghana\"}_{loc_id}.npz'))\n",
        "        dates_idx = self.get_dates(loc_id)\n",
        "\n",
        "        s1 = images['s1']\n",
        "        s2 = images['s2']\n",
        "        planet = images['planet']\n",
        "\n",
        "        s1 = torch.from_numpy(s1)\n",
        "        s2 = torch.from_numpy(s2.astype(np.int32))\n",
        "        planet = torch.from_numpy(planet.astype(np.int32))\n",
        "\n",
        "        planet = planet.permute(3, 0, 1, 2)\n",
        "        planet = transforms.CenterCrop(128)(planet)\n",
        "        planet = planet.permute(1, 2, 3, 0)\n",
        "\n",
        "        # Normalization\n",
        "        s1 = self.normalization(s1, 's1')\n",
        "        s2 = self.normalization(s2, 's2')\n",
        "        planet = self.normalization(planet, 'planet')\n",
        "\n",
        "        s1 = s1[:,:,:,dates_idx[\"s1_min\"]:dates_idx[\"s1_max\"]]\n",
        "        s2 = s2[:,:,:,dates_idx[\"s2_min\"]:dates_idx[\"s2_max\"]]\n",
        "        planet = planet[:,:,:,dates_idx[\"planet_min\"]:dates_idx[\"planet_max\"]]\n",
        "\n",
        "        planet = torch.mean(planet, axis=-1)\n",
        "        s1 = torch.mean(s1, axis=-1)\n",
        "        s2 = torch.mean(s2, axis=-1)\n",
        "\n",
        "        return {'s1': torch.tensor(s1, dtype=torch.float32), 's2': torch.tensor(s2, dtype=torch.float32), 'planet': torch.tensor(planet, dtype=torch.float32)}\n",
        "\n",
        "    def get_label(self, idx):\n",
        "        \"\"\"\n",
        "        Returns y for a given idx.\n",
        "        \"\"\"\n",
        "        loc_id = f'{self.y_array[idx]:06d}'\n",
        "        label = np.load(os.path.join(self.data_dir, 'ghana', 'truth', f'{\"ghana\"}_{loc_id}.npz'))['truth']\n",
        "        label = torch.from_numpy(label)\n",
        "        label[label>4]=0\n",
        "        return label\n",
        "\n",
        "    def get_dates(self, loc_id):\n",
        "        \"\"\"\n",
        "        Converts json dates into tensor containing dates\n",
        "        \"\"\"\n",
        "        s1_json = json.loads(open(os.path.join(self.data_dir, 'ghana', 's1', f\"s1_{'ghana'}_{loc_id}.json\"), 'r').read())\n",
        "        s1 = s1_json['dates']\n",
        "\n",
        "        s1 =np.array([datetime.strptime(date, \"%Y-%m-%d\") for date in s1])\n",
        "        s1_date_low = s1[s1 >= datetime.strptime('2016-05-01', \"%Y-%m-%d\")]\n",
        "        s1_date_high = s1_date_low[s1_date_low<= datetime.strptime('2016-11-30', \"%Y-%m-%d\")]\n",
        "        s1_idx_min = np.where(s1==s1_date_high[0])\n",
        "        s1_idx_max = np.where(s1==s1_date_high[-1])\n",
        "        s1_idx_min = s1_idx_min[0][0]\n",
        "        s1_idx_max = s1_idx_max[0][0]\n",
        "\n",
        "\n",
        "        s2_json = json.loads(open(os.path.join(self.data_dir, 'ghana', 's2', f\"s2_{'ghana'}_{loc_id}.json\"), 'r').read())\n",
        "        s2 = s2_json['dates']\n",
        "\n",
        "        s2 =np.array([datetime.strptime(date, \"%Y-%m-%d\") for date in s2])\n",
        "        s2_date_low = s2[s2 >= datetime.strptime('2016-05-01', \"%Y-%m-%d\")]\n",
        "        s2_date_high = s2_date_low[s2_date_low<= datetime.strptime('2016-11-30', \"%Y-%m-%d\")]\n",
        "        s2_idx_min = np.where(s2==s2_date_high[0])\n",
        "        s2_idx_max = np.where(s2==s2_date_high[-1])\n",
        "        s2_idx_min = s2_idx_min[0][0]\n",
        "        s2_idx_max = s2_idx_max[0][0]\n",
        "\n",
        "        planet_json = json.loads(open(os.path.join(self.data_dir, 'ghana', 'planet', f\"planet_{'ghana'}_{loc_id}.json\"), 'r').read())\n",
        "        planet = planet_json['dates']\n",
        "\n",
        "        planet =np.array([datetime.strptime(date, \"%Y-%m-%d\") for date in planet])\n",
        "        planet_date_low = planet[planet >= datetime.strptime('2017-05-01', \"%Y-%m-%d\")]\n",
        "        planet_date_high = planet_date_low[planet_date_low<= datetime.strptime('2017-11-30', \"%Y-%m-%d\")]\n",
        "        planet_idx_min = np.where(planet==planet_date_high[0])\n",
        "        planet_idx_max = np.where(planet==planet_date_high[-1])\n",
        "        planet_idx_min = planet_idx_min[0][0]\n",
        "        planet_idx_max = planet_idx_max[0][0]\n",
        "\n",
        "        return {\"s1_min\":s1_idx_min, \"s1_max\":s1_idx_max, \"s2_min\":s2_idx_min,\"s2_max\":s2_idx_max,\"planet_min\":planet_idx_min,\"planet_max\":planet_idx_max}\n",
        "\n",
        "    def normalization(self, grid, satellite):\n",
        "        \"\"\" Normalization based on values defined in constants.py\n",
        "        Args:\n",
        "          grid - (tensor) grid to be normalized\n",
        "          satellite - (str) describes source that grid is from (\"s1\" or \"s2\")\n",
        "        Returns:\n",
        "          grid - (tensor) a normalized version of the input grid\n",
        "        \"\"\"\n",
        "        num_bands = grid.shape[0]\n",
        "        means = MEANS[satellite]['ghana']\n",
        "        stds = STDS[satellite]['ghana']\n",
        "        grid = (grid-means[:num_bands].reshape(num_bands, 1, 1, 1))/stds[:num_bands].reshape(num_bands, 1, 1, 1)\n",
        "\n",
        "        if satellite not in ['s1', 's2', 'planet']:\n",
        "            raise ValueError(\"Incorrect normalization parameters\")\n",
        "        return grid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cYQ28yM-Uh1U"
      },
      "outputs": [],
      "source": [
        "class SustainBenchSubset(CropTypeMappingDataset):\n",
        "    def __init__(self, dataset, split, transform=None):\n",
        "        \"\"\"\n",
        "        This acts like torch.utils.data.Subset, but on SustainBenchDatasets.\n",
        "        We pass in transform explicitly because it can potentially vary at\n",
        "        training vs. test time, if we're using data augmentation.\n",
        "\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.dataset = dataset\n",
        "        self.transform = transform\n",
        "\n",
        "        split_mask = self.split_array == self.split_dict[split]\n",
        "        self.indices = np.where(split_mask)[0]\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        x, y= self.dataset[self.indices[idx]]\n",
        "        if self.transform is not None:\n",
        "            x = self.transform(x)\n",
        "        return x, y\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.indices)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ne5kcG3f504w"
      },
      "outputs": [],
      "source": [
        "dataset = CropTypeMappingDataset()\n",
        "\n",
        "train_dataset = SustainBenchSubset(dataset, 'train')\n",
        "val_dataset = SustainBenchSubset(dataset, 'val')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z-LJe67O2ese"
      },
      "outputs": [],
      "source": [
        "train_loader = DataLoader(\n",
        "                train_dataset,\n",
        "                shuffle=True, # Shuffle training dataset\n",
        "                sampler=None,\n",
        "                num_workers = 2,\n",
        "                batch_size=9)\n",
        "\n",
        "val_loader = DataLoader(\n",
        "                val_dataset,\n",
        "                shuffle=False, # Do not shuffle eval datasets\n",
        "                sampler=None,\n",
        "                num_workers = 2,\n",
        "                batch_size=9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1At28FaU4MwI",
        "outputId": "a7e0d55f-a995-4cad-ed96-2497ec1e0bb7"
      },
      "outputs": [],
      "source": [
        "for x,y in train_loader:\n",
        "  print(x['planet'].shape)\n",
        "  break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AlRsC3QCvWXm"
      },
      "source": [
        "## 2D_UNET Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MEgIDShi4LEg"
      },
      "outputs": [],
      "source": [
        "def conv(ch_in, ch_out, kernel_size=3,stride=1, padding=1):\n",
        "\n",
        "  return nn.Sequential(\n",
        "      nn.Conv2d(in_channels=ch_in, out_channels=ch_in, kernel_size=kernel_size,\n",
        "                               stride=stride, padding=padding),\n",
        "      nn.BatchNorm2d(ch_in),\n",
        "      nn.LeakyReLU(inplace=True),\n",
        "      nn.Conv2d(in_channels=ch_in, out_channels=ch_out, kernel_size=kernel_size,\n",
        "                               stride=stride, padding=padding),\n",
        "      nn.BatchNorm2d(ch_out),\n",
        "      nn.LeakyReLU(inplace=True),\n",
        "      nn.Conv2d(in_channels=ch_out, out_channels=ch_out, kernel_size=kernel_size,\n",
        "                               stride=stride, padding=padding),\n",
        "      nn.BatchNorm2d(ch_out),\n",
        "      nn.LeakyReLU(inplace=True),\n",
        "  )\n",
        "\n",
        "def upconv(ch_in, ch_out, kernel_size=3,stride=1, padding=1):\n",
        "\n",
        "  return nn.Sequential(\n",
        "      nn.Conv2d(in_channels=ch_in, out_channels=ch_out, kernel_size=kernel_size,\n",
        "                               stride=stride, padding=padding),\n",
        "      nn.BatchNorm2d(ch_out),\n",
        "      nn.LeakyReLU(inplace=True),\n",
        "\n",
        "  )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2_L4UnI_4ZEO"
      },
      "outputs": [],
      "source": [
        "class UNet_planet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # Encoder S2\n",
        "        self.convs20 = conv(ch_in=10, ch_out=64)\n",
        "        self.maxpool20 = nn.MaxPool2d(kernel_size=2, stride=2,padding=0)\n",
        "        self.convs21_1_=conv(ch_in=64, ch_out=64)\n",
        "        self.convs21_2=conv(ch_in=64, ch_out=64)\n",
        "\n",
        "        self.maxpool21 = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
        "        self.convs22_1=conv(ch_in=64, ch_out=128)\n",
        "        self.convs22_2=conv(ch_in=128, ch_out=128)\n",
        "\n",
        "        self.maxpool22 = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
        "        self.convs23=conv(ch_in=128, ch_out=256)\n",
        "        # decoder S2\n",
        "        self.upconvs23 = upconv(ch_in=256, ch_out=256)\n",
        "        self.transConvs23 = nn.ConvTranspose2d(in_channels=256, out_channels=128, kernel_size=3,\n",
        "                               stride=2, padding=1, output_padding=1)\n",
        "\n",
        "        self.upconvs22_2=upconv(ch_in=256, ch_out=128) # 128+128, 128\n",
        "        self.upconvs22_1=upconv(ch_in=128, ch_out=128)\n",
        "        self.transConvs22 = nn.ConvTranspose2d(in_channels=128, out_channels=64, kernel_size=3,\n",
        "                               stride=2, padding=1, output_padding=1)\n",
        "\n",
        "        self.upconvs21_2=upconv(ch_in=128, ch_out=64) # 64+64, 64\n",
        "        self.upconvs21_1=upconv(ch_in=64, ch_out=32)\n",
        "        self.upconvs2_nc=upconv(ch_in=32, ch_out=5)\n",
        "\n",
        "        # Encoder S1\n",
        "        self.convs10 = conv(ch_in=3, ch_out=64, kernel_size=3,stride=1, padding=1)\n",
        "        self.maxpool10 = nn.MaxPool2d(kernel_size=2, stride=2,padding=0)\n",
        "        self.convs11_1_=conv(ch_in=64, ch_out=64, kernel_size=3,stride=1, padding=1)\n",
        "        self.convs11_2=conv(ch_in=64, ch_out=64, kernel_size=3,stride=1, padding=1)\n",
        "\n",
        "        self.maxpool11 = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
        "        self.convs12_1=conv(ch_in=64, ch_out=128, kernel_size=3,stride=1, padding=1)\n",
        "        self.convs12_2=conv(ch_in=128, ch_out=128, kernel_size=3,stride=1, padding=1)\n",
        "\n",
        "        self.maxpool12 = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
        "        self.convs13=conv(ch_in=128, ch_out=256, kernel_size=3,stride=1, padding=1)\n",
        "\n",
        "        # decoder S1\n",
        "        self.upconvs13 = upconv(ch_in=256, ch_out=256)\n",
        "        self.transConvs13 = nn.ConvTranspose2d(in_channels=256, out_channels=128, kernel_size=3,\n",
        "                               stride=2, padding=1, output_padding=1)\n",
        "\n",
        "        self.upconvs12_2=upconv(ch_in=256, ch_out=128) # 128+128, 128\n",
        "        self.upconvs12_1=upconv(ch_in=128, ch_out=128)\n",
        "        self.transConvs12 = nn.ConvTranspose2d(in_channels=128, out_channels=64, kernel_size=3,\n",
        "                               stride=2, padding=1, output_padding=1)\n",
        "\n",
        "        self.upconvs11_2=upconv(ch_in=128, ch_out=64) # 64+64, 64\n",
        "        self.upconvs11_1=upconv(ch_in=64, ch_out=32)\n",
        "        self.upconvs1_nc=upconv(ch_in=32, ch_out=5)\n",
        "\n",
        "        # Encoder planet\n",
        "        self.convsp1_1=conv(ch_in=4, ch_out=16, kernel_size=3,stride=1, padding=1)\n",
        "        self.convsp1_2=conv(ch_in=16, ch_out=16, kernel_size=3,stride=1, padding=1)\n",
        "        self.maxpoolp1 = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
        "        self.maxpoolp1_1 = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
        "\n",
        "        self.convsp2_1=conv(ch_in=16, ch_out=32, kernel_size=3,stride=1, padding=1)\n",
        "        self.convsp2_2=conv(ch_in=32, ch_out=32, kernel_size=3,stride=1, padding=1)\n",
        "        self.maxpoolp2 = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
        "\n",
        "        self.convsp3_1=conv(ch_in=32, ch_out=64, kernel_size=3,stride=1, padding=1)\n",
        "        self.convsp3_2=conv(ch_in=64, ch_out=64, kernel_size=3,stride=1, padding=1)\n",
        "\n",
        "        self.maxpoolp3 = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
        "        self.convsp4_1=conv(ch_in=64, ch_out=128, kernel_size=3,stride=1, padding=1)\n",
        "        self.convsp4_2=conv(ch_in=128, ch_out=128, kernel_size=3,stride=1, padding=1)\n",
        "\n",
        "        self.maxpoolp4 = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
        "        self.convsp5=conv(ch_in=128, ch_out=256, kernel_size=3,stride=1, padding=1)\n",
        "\n",
        "        # Decoder planet\n",
        "        self.upconvsp3 = upconv(ch_in=256, ch_out=256)\n",
        "        self.transConvsp3 = nn.ConvTranspose2d(in_channels=256, out_channels=128, kernel_size=3,\n",
        "                               stride=2, padding=1, output_padding=1)\n",
        "\n",
        "        self.upconvsp2_2=upconv(ch_in=256, ch_out=128) # 128+128, 128\n",
        "        self.upconvsp2_1=upconv(ch_in=128, ch_out=128)\n",
        "        self.transConvsp2 = nn.ConvTranspose2d(in_channels=128, out_channels=64, kernel_size=3,\n",
        "                               stride=2, padding=1, output_padding=1)\n",
        "\n",
        "        self.upconvsp1_2=upconv(ch_in=176, ch_out=64) # 112+64, 64\n",
        "        self.upconvsp1_1=upconv(ch_in=64, ch_out=32)\n",
        "        self.upconvsp_nc=upconv(ch_in=32, ch_out=5)\n",
        "\n",
        "        self.final=nn.ConvTranspose2d(in_channels=15, out_channels=5, kernel_size=3,\n",
        "                               stride=2, padding=1, output_padding=1)\n",
        "\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, X):\n",
        "        X['s2'][torch.isnan(X['s2'])]=0\n",
        "        X['s1'][torch.isnan(X['s1'])]=0\n",
        "        X['planet'][torch.isnan(X['planet'])]=0\n",
        "        # S2\n",
        "        # encoder\n",
        "        layer02 = self.convs20(X['s2'].to('cuda'))\n",
        "        layer12 = self.convs21_1_(self.maxpool20(layer02))\n",
        "        layer22 = self.convs21_2(layer12)\n",
        "        layer32 = self.convs22_1(self.maxpool21(layer22))\n",
        "        layer42 = self.convs22_2(layer32)\n",
        "        layer52 = self.convs23(self.maxpool22(layer42))\n",
        "        # decoder\n",
        "        x2 = self.upconvs23(layer52)\n",
        "        x2 = self.transConvs23(x2)\n",
        "        x2 = torch.cat([x2, layer42], dim=1)\n",
        "        x2 = self.upconvs22_2(x2)\n",
        "        x2 = self.upconvs22_1(x2)\n",
        "        x2 = self.transConvs22(x2)\n",
        "        x2 = torch.cat([x2, layer22], dim=1)\n",
        "        x2 = self.upconvs21_2(x2)\n",
        "        x2 = self.upconvs21_1(x2)\n",
        "        x2f = self.upconvs2_nc(x2)\n",
        "\n",
        "        # S1\n",
        "        #Encoder\n",
        "        layer01 = self.convs10(X['s1'].to('cuda'))\n",
        "        layer11 = self.convs11_1_(self.maxpool10(layer01))\n",
        "        layer21 = self.convs11_2(layer11)\n",
        "        layer31 = self.convs12_1(self.maxpool11(layer21))\n",
        "        layer41 = self.convs12_2(layer31)\n",
        "        layer51 = self.convs13(self.maxpool12(layer41))\n",
        "        # decoder\n",
        "        x1 = self.upconvs13(layer51)\n",
        "        x1 = self.transConvs13(x1)\n",
        "        x1 = torch.cat([x1, layer41], dim=1)\n",
        "        x1 = self.upconvs12_2(x1)\n",
        "        x1 = self.upconvs12_1(x1)\n",
        "        x1 = self.transConvs12(x1)\n",
        "        x1 = torch.cat([x1, layer21], dim=1)\n",
        "        x1 = self.upconvs11_2(x1)\n",
        "        x1 = self.upconvs11_1(x1)\n",
        "        x1f = self.upconvs1_nc(x1)\n",
        "\n",
        "        # Planet\n",
        "        # Encoder\n",
        "        layerp0 = self.convsp1_1(X['planet'].to('cuda'))\n",
        "        layerp1 = self.convsp1_2(layerp0)\n",
        "        maxp1 = self.maxpoolp1(layerp1)\n",
        "        maxp1_1 = self.maxpoolp1(maxp1)\n",
        "\n",
        "        layerp2 = self.convsp2_1(maxp1)\n",
        "        layerp3 = self.convsp2_2(layerp2)\n",
        "        maxp2 = self.maxpoolp2(layerp3)\n",
        "\n",
        "        layerp4 = self.convsp3_1(maxp2)\n",
        "        layerp5 = self.convsp3_2(layerp4)\n",
        "\n",
        "        layerp6 = self.convsp4_1(self.maxpoolp3(layerp5))\n",
        "        layerp7 = self.convsp4_2(layerp6)\n",
        "\n",
        "        layerp8 = self.convsp5(self.maxpoolp4(layerp7))\n",
        "\n",
        "        # decoder\n",
        "        x = self.upconvsp3(layerp8)\n",
        "        x = self.transConvsp3(x)\n",
        "        x = torch.cat([x, layerp7], dim=1)\n",
        "        x = self.upconvsp2_2(x)\n",
        "        x = self.upconvsp2_1(x)\n",
        "        x = self.transConvsp2(x)\n",
        "        x = torch.cat([x, layerp5, maxp1_1, maxp2], dim=1)\n",
        "        x = self.upconvsp1_2(x)\n",
        "        x = self.upconvsp1_1(x)\n",
        "        xpf = self.upconvsp_nc(x)\n",
        "\n",
        "        out = self.final(torch.cat([x1f, x2f, xpf], dim=1))\n",
        "\n",
        "        return self.softmax(out)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YflCiStTqz1p"
      },
      "outputs": [],
      "source": [
        "# Model object\n",
        "model_2d_unet = UNet_planet().to('cuda')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QQMrjeTmrDjJ"
      },
      "outputs": [],
      "source": [
        "loss_weights = 1 - np.array([.85, .17, .56, .16, .11])\n",
        "loss_weights = torch.tensor(loss_weights, dtype=torch.float32).cuda()\n",
        "\n",
        "config = {\n",
        "    \"epochs\"           : 100,\n",
        "    \"lr\"               : 0.001,\n",
        "    \"label_smoothing\"  : 0.2,\n",
        "    \"momentum\"         : 0.9,\n",
        "    \"weight_decay\"     : 0.0001,\n",
        "    \"loss_weights\"     : loss_weights\n",
        "}\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zMFZ5Q3UesvA"
      },
      "source": [
        "#### Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wki28zN9esvA",
        "outputId": "e0b8e875-531f-479e-8364-cbad9b912a7c"
      },
      "outputs": [],
      "source": [
        "wandb.login(key=\"ed120be65ed3b503c10399eb93a51f7112e342dc\") #API Key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "id": "PFYxzckHXq4_",
        "outputId": "0dd3f747-1717-4879-b644-69e265cc28dc"
      },
      "outputs": [],
      "source": [
        "run = wandb.init(\n",
        "    name = \"UNET_2D-Ghana\", ## Wandb creates random run names if you skip this field\n",
        "    reinit = True, ### Allows reinitalizing runs when you re-run this cell\n",
        "    # id ='vxx60mpj', ### Insert specific run id here if you want to resume a previous run\n",
        "    # resume = \"must\", ### You need this to resume previous runs, but comment out reinit = True when using this\n",
        "    project = \"Crop-type-segmentation\", ### Project should be created in your wandb account\n",
        "     ### Wandb Config for your run\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GSyt3BWE9RzM",
        "outputId": "b666e93f-c948-4610-f0b9-35be062bfee9"
      },
      "outputs": [],
      "source": [
        "import gc\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WdzAvndyp9RJ"
      },
      "outputs": [],
      "source": [
        "# metrics, train and validation functions\n",
        "def reshapeForLoss(y):\n",
        "    \"\"\" Reshapes labels or preds for loss fn.\n",
        "    To get them to the correct shape, we permute:\n",
        "      [batch x classes x rows x cols] --> [batch x rows x cols x classes]\n",
        "      and then reshape to [N x classes], where N = batch*rows*cols\n",
        "    \"\"\"\n",
        "    # [batch x classes x rows x cols] --> [batch x rows x cols x classes]\n",
        "    y = y.permute(0, 2, 3, 1)\n",
        "    # [batch x rows x cols x classes] --> [batch*rows*cols x classes]\n",
        "    y = y.contiguous().view(-1, y.shape[3])\n",
        "    return y\n",
        "\n",
        "def mask_ce_loss(y_true, y_pred, weight_scale=1):\n",
        "\n",
        "    y_true = reshapeForLoss(y_true)\n",
        "    num_examples = torch.sum(y_true, dtype=torch.float32).cuda()\n",
        "    y_pred = reshapeForLoss(y_pred)\n",
        "\n",
        "    loss_mask = torch.sum(y_true, dim=1).type(torch.LongTensor)\n",
        "    loss_mask_repeat = loss_mask.unsqueeze(1).repeat(1,y_pred.shape[1]).type(torch.FloatTensor)\n",
        "    _, y_true = torch.max(y_true, dim=1)\n",
        "    y_true = y_true * loss_mask\n",
        "    y_pred_ = y_pred * loss_mask_repeat.cuda()\n",
        "\n",
        "\n",
        "    loss_fn = nn.NLLLoss(weight = config[\"loss_weights\"] ** weight_scale)\n",
        "\n",
        "    total_loss = torch.sum(loss_fn(y_pred, y_true.cuda()))\n",
        "\n",
        "    if num_examples == 0:\n",
        "        print(\"WARNING: NUMBER OF EXAMPLES IS 0\")\n",
        "\n",
        "    else: return total_loss / num_examples\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FugQI96hjnmz"
      },
      "outputs": [],
      "source": [
        "# loss_fn = torch.nn.CrossEntropyLoss(label_smoothing=config[\"label_smoothing\"], weight=config[\"loss_weights\"])\n",
        "optimizer = torch.optim.SGD(model_2d_unet.parameters(), lr=config[\"lr\"], momentum=config[\"momentum\"], weight_decay=config[\"weight_decay\"])\n",
        "\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=100, eta_min=0.00005)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rMU5b1M6sq5x"
      },
      "outputs": [],
      "source": [
        "# metrics, train and validation functions\n",
        "\n",
        "# Metrics\n",
        "def crop_segmentation_metrics(y_true, y_pred):\n",
        "        y_true = reshapeForLoss(y_true.cpu())\n",
        "        y_pred = reshapeForLoss(y_pred.cpu())\n",
        "\n",
        "        loss_mask = torch.sum(y_true, dim=1).type(torch.LongTensor)\n",
        "\n",
        "        _, y_true = torch.max(y_true, dim=1)\n",
        "        _, y_pred = torch.max(y_pred, dim=1)\n",
        "\n",
        "        y_true = y_true[loss_mask == 1]\n",
        "        y_pred = y_pred[loss_mask == 1]\n",
        "\n",
        "        assert (y_true.shape == y_pred.shape)\n",
        "        y_true = y_true.int()\n",
        "        y_pred = y_pred.int()\n",
        "        f1 = f1_score(y_true, y_pred, average='macro')\n",
        "        acc = accuracy_score(y_true, y_pred)\n",
        "        cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "        return f1, acc, cm\n",
        "\n",
        "# Train\n",
        "def train_step(data_loader, optimizer, accuracy_fn):\n",
        "  \"\"\"Performs a training with model trying to learn on data-loader\"\"\"\n",
        "\n",
        "  curr_lr = float(optimizer.param_groups[0]['lr'])\n",
        "  model_2d_unet.train() # Put model into training mode\n",
        "\n",
        "  train_loss, train_acc, train_f1=0,0,0\n",
        "  # Add a loop to loop through the training batches\n",
        "  for img,label in tqdm(data_loader):\n",
        "\n",
        "    # 1. Forwad pass\n",
        "    y_pred=model_2d_unet(img)\n",
        "\n",
        "    # 2. Calculate loss and accuracy (per batch)\n",
        "    label = label.long()\n",
        "    label = torch.nn.functional.one_hot(label, num_classes=5).permute([0,3,1,2])\n",
        "\n",
        "\n",
        "    loss=mask_ce_loss(label, y_pred)\n",
        "\n",
        "    train_loss+=loss.item() #  accumulate training loss\n",
        "    # y_pred_masked = torch.max(y_pred,dim=1)[1]\n",
        "    train_acc += accuracy_fn(y_true=label, y_pred=y_pred)[1]\n",
        "    train_f1+=accuracy_fn(y_true=label, y_pred=y_pred)[0]\n",
        "\n",
        "    # 3. optimize zero grad\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # 4. Loss backward\n",
        "    loss.backward()\n",
        "\n",
        "    # 5. Optimizer step\n",
        "    optimizer.step()\n",
        "\n",
        "\n",
        "  # Divide total train loss and acc by lenth of train dataloader\n",
        "  train_loss/=len(data_loader)\n",
        "  train_acc/=len(data_loader)\n",
        "  train_f1/=len(data_loader)\n",
        "  print(f\"Train loss {train_loss: .5f}|Train acc : {train_acc:.5f} | Train f1: {train_f1:.5f} | lr: {curr_lr}\\n\")\n",
        "  return train_loss, train_acc, train_f1, curr_lr\n",
        "\n",
        "# Validation\n",
        "def validation_step(data_loader, accuracy_fn):\n",
        "  \"\"\"Performs a tesing loop step on model going over data loader.\"\"\"\n",
        "\n",
        "  val_loss,val_acc, val_f1=0,0,0\n",
        "\n",
        "  model_2d_unet.eval() # put the model in eval mode\n",
        "  # turn on inference mode context manager\n",
        "  with torch.inference_mode():\n",
        "    for img,label in tqdm(data_loader):\n",
        "\n",
        "        # 1. Forward pass (outputs raw logits)\n",
        "      val_pred=model_2d_unet(img)\n",
        "\n",
        "      # 2. Calculate the loss/acc\n",
        "      label = label.long()\n",
        "      label = torch.nn.functional.one_hot(label, num_classes=5).permute([0,3,1,2])\n",
        "      val_loss+=mask_ce_loss(label, val_pred)\n",
        "\n",
        "      # val_pred_masked = torch.max(val_pred,dim=1)[1]\n",
        "      val_acc += accuracy_fn(y_true=label, y_pred=val_pred)[1]\n",
        "      val_f1+=accuracy_fn(y_true=label, y_pred=val_pred)[0]\n",
        "\n",
        "    # Adjust metrics and print out\n",
        "    val_loss/=len(data_loader)\n",
        "    val_acc/=len(data_loader)\n",
        "    val_f1/=len(data_loader)\n",
        "    print(f\"Val loss: {val_loss:.5f} | Val acc: {val_acc:.5f} | Val f1: {val_f1:.5f}\\n\")\n",
        "\n",
        "    return val_loss, val_acc, val_f1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "ue9jxHh94Ism",
        "outputId": "66d3c684-f87e-4784-fbc4-dce70bb6fa66"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Let's train\n",
        "epochs=config['epochs']\n",
        "\n",
        "# Create an optimization and evluation using train_step() and val_step()\n",
        "train_loss_list=[]\n",
        "train_acc_list=[]\n",
        "train_f1_list=[]\n",
        "\n",
        "val_loss_list=[]\n",
        "val_acc_list=[]\n",
        "val_f1_list=[]\n",
        "\n",
        "\n",
        "best_val_f1 = float('inf')\n",
        "\n",
        "for epoch in range(epochs):\n",
        "\n",
        "  print(f\"Epoch: {epoch}/{epochs} \\n----------------\")\n",
        "\n",
        "\n",
        "  train_loss, train_acc, train_f1, curr_lr = train_step(\n",
        "                                                data_loader=train_loader,\n",
        "                                                optimizer=optimizer,\n",
        "                                                accuracy_fn=crop_segmentation_metrics\n",
        "                                                )\n",
        "  train_loss_list.append(train_loss)\n",
        "  train_acc_list.append(train_acc)\n",
        "  train_f1_list.append(train_f1)\n",
        "\n",
        "  val_loss, val_acc, val_f1 = validation_step(\n",
        "                                            data_loader=val_loader,\n",
        "                                            accuracy_fn=crop_segmentation_metrics,\n",
        "                                            )\n",
        "  val_loss_list.append(val_loss)\n",
        "  val_acc_list.append(val_acc)\n",
        "  val_f1_list.append(val_f1)\n",
        "\n",
        "  wandb.log({\"train_loss\": train_loss, 'train_f1': train_f1, 'train_acc': train_acc, 'validation_f1':val_f1,\n",
        "               'validation_loss': val_loss, 'validation_acc': val_acc, \"learning_Rate\": curr_lr})\n",
        "\n",
        "  if val_f1 < best_val_f1:\n",
        "      best_val_loss = val_f1\n",
        "      torch.save(model_2d_unet.state_dict(), '/content/models/best.pth')  # Save the best model\n",
        "\n",
        "      print(\"Saving model\")\n",
        "      torch.save({'model_state_dict':model_2d_unet.state_dict(),\n",
        "                'optimizer_state_dict':optimizer.state_dict(),\n",
        "                'scheduler_state_dict':scheduler.state_dict(),\n",
        "                'best_val_loss': best_val_loss,\n",
        "                'epoch': epoch}, '/content/models/best.pth')\n",
        "\n",
        "      wandb.save('/content/models/best.pth')\n",
        "\n",
        "  scheduler.step()\n",
        "\n",
        "run.finish()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
